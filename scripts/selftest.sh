#!/bin/bash

# å…¨é“¾è·¯è‡ªæµ‹è„šæœ¬
# åŠŸèƒ½: reset â†’ é€ æ•° â†’ PSIå¯¹é½ â†’ è®­ç»ƒ â†’ è¯„ä¼° â†’ å¯åŠ¨æœåŠ¡ â†’ è¯„åˆ† â†’ å®¡è®¡ â†’ ç”ŸæˆæŠ¥å‘Š

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# é…ç½®å‚æ•°
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
DATA_DIR="$PROJECT_ROOT/data"
REPORTS_DIR="$PROJECT_ROOT/reports"
TOOLS_DIR="$PROJECT_ROOT/tools"
SCRIPTS_DIR="$PROJECT_ROOT/scripts"

# æµ‹è¯•å‚æ•°
SAMPLE_SIZE=50000
OVERLAP_RATIO=0.6
PARTIES="A,B"
SEED=42
BAD_RATE=0.12
NOISE_LEVEL=0.15

# æœåŠ¡ç«¯å£
CONSENT_PORT=8000
PSI_PORT=8001
TRAINER_PORT=8002
FRONTEND_PORT=3000

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    log_info "æ£€æŸ¥ä¾èµ–..."
    
    # æ£€æŸ¥Python
    if ! command -v python3 &> /dev/null; then
        log_error "Python3 æœªå®‰è£…"
        exit 1
    fi
    
    # æ£€æŸ¥Node.js
    if ! command -v node &> /dev/null; then
        log_error "Node.js æœªå®‰è£…"
        exit 1
    fi
    
    # æ£€æŸ¥å¿…éœ€çš„PythonåŒ…
    python3 -c "import pandas, numpy, sklearn, scipy" 2>/dev/null || {
        log_error "ç¼ºå°‘å¿…éœ€çš„PythonåŒ…ï¼Œè¯·è¿è¡Œ: pip install pandas numpy scikit-learn scipy"
        exit 1
    }
    
    log_success "ä¾èµ–æ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_service() {
    local port=$1
    local service_name=$2
    
    if curl -s "http://localhost:$port/health" > /dev/null 2>&1; then
        log_success "$service_name æœåŠ¡è¿è¡Œæ­£å¸¸ (ç«¯å£ $port)"
        return 0
    else
        log_warning "$service_name æœåŠ¡æœªè¿è¡Œ (ç«¯å£ $port)"
        return 1
    fi
}

# ç­‰å¾…æœåŠ¡å¯åŠ¨
wait_for_service() {
    local port=$1
    local service_name=$2
    local max_wait=30
    local count=0
    
    log_info "ç­‰å¾… $service_name æœåŠ¡å¯åŠ¨..."
    
    while [ $count -lt $max_wait ]; do
        if curl -s "http://localhost:$port/health" > /dev/null 2>&1; then
            log_success "$service_name æœåŠ¡å·²å¯åŠ¨"
            return 0
        fi
        sleep 1
        count=$((count + 1))
    done
    
    log_error "$service_name æœåŠ¡å¯åŠ¨è¶…æ—¶"
    return 1
}

# é‡ç½®ç¯å¢ƒ
reset_environment() {
    log_info "é‡ç½®æµ‹è¯•ç¯å¢ƒ..."
    
    # æ¸…ç†æ•°æ®ç›®å½•
    rm -rf "$DATA_DIR"/*.csv
    rm -rf "$DATA_DIR"/*.json
    rm -rf "$DATA_DIR"/psi_*
    
    # æ¸…ç†æŠ¥å‘Šç›®å½•
    rm -rf "$REPORTS_DIR"/*
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    mkdir -p "$DATA_DIR" "$REPORTS_DIR"
    
    log_success "ç¯å¢ƒé‡ç½®å®Œæˆ"
}

# ç”Ÿæˆåˆæˆæ•°æ®
generate_synthetic_data() {
    log_info "ç”Ÿæˆåˆæˆæ•°æ®..."
    
    cd "$PROJECT_ROOT"
    
    # è¿è¡Œæ•°æ®ç”Ÿæˆå™¨
    python3 "$TOOLS_DIR/seed/synth_vertical_v2.py" \
        --n $SAMPLE_SIZE \
        --overlap $OVERLAP_RATIO \
        --parties $PARTIES \
        --seed $SEED \
        --bad_rate $BAD_RATE \
        --noise $NOISE_LEVEL
    
    if [ $? -eq 0 ]; then
        log_success "åˆæˆæ•°æ®ç”Ÿæˆå®Œæˆ"
    else
        log_error "åˆæˆæ•°æ®ç”Ÿæˆå¤±è´¥"
        exit 1
    fi
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    local expected_files=("partyA_bank.csv" "partyB_ecom.csv")
    for file in "${expected_files[@]}"; do
        if [ ! -f "$DATA_DIR/$file" ]; then
            log_error "ç¼ºå°‘æ•°æ®æ–‡ä»¶: $file"
            exit 1
        fi
        
        local line_count=$(wc -l < "$DATA_DIR/$file")
        log_info "$file: $line_count è¡Œ"
    done
}

# éªŒè¯æ•°æ®åˆçº¦
validate_data_contract() {
    log_info "éªŒè¯æ•°æ®åˆçº¦..."
    
    cd "$PROJECT_ROOT"
    
    # è¿è¡Œæ•°æ®åˆçº¦æ ¡éªŒ
    python3 "$TOOLS_DIR/contract/data_contract.py" \
        --files "$DATA_DIR/partyA_bank.csv" "$DATA_DIR/partyB_ecom.csv" \
        --output "$REPORTS_DIR/data_profile.json" \
        --strict
    
    if [ $? -eq 0 ]; then
        log_success "æ•°æ®åˆçº¦éªŒè¯é€šè¿‡"
    else
        log_error "æ•°æ®åˆçº¦éªŒè¯å¤±è´¥"
        exit 1
    fi
}

# æ‰§è¡ŒPSIå¯¹é½
perform_psi_alignment() {
    log_info "æ‰§è¡ŒPSIå¯¹é½..."
    
    # æ£€æŸ¥PSIæœåŠ¡
    if ! check_service $PSI_PORT "PSI"; then
        log_error "PSIæœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡"
        exit 1
    fi
    
    # åˆ›å»ºPSIä¼šè¯
    local session_response=$(curl -s -X POST "http://localhost:$PSI_PORT/psi/sessions" \
        -H "Content-Type: application/json" \
        -d '{
            "session_id": "selftest_session",
            "parties": ["bank", "ecom"],
            "algorithm": "ecdh"
        }')
    
    if echo "$session_response" | grep -q "session_id"; then
        log_success "PSIä¼šè¯åˆ›å»ºæˆåŠŸ"
    else
        log_error "PSIä¼šè¯åˆ›å»ºå¤±è´¥: $session_response"
        exit 1
    fi
    
    # ä¸Šä¼ é“¶è¡Œæ–¹æ•°æ®
    log_info "ä¸Šä¼ é“¶è¡Œæ–¹PSIæ•°æ®..."
    local bank_psi_data=$(python3 -c "
import pandas as pd
import json
df = pd.read_csv('$DATA_DIR/partyA_bank.csv')
data = {'identifiers': df['psi_token'].tolist()}
print(json.dumps(data))
")
    
    curl -s -X POST "http://localhost:$PSI_PORT/psi/sessions/selftest_session/upload" \
        -H "Content-Type: application/json" \
        -d "{\"party\": \"bank\", \"data\": $bank_psi_data}" > /dev/null
    
    # ä¸Šä¼ ç”µå•†æ–¹æ•°æ®
    log_info "ä¸Šä¼ ç”µå•†æ–¹PSIæ•°æ®..."
    local ecom_psi_data=$(python3 -c "
import pandas as pd
import json
df = pd.read_csv('$DATA_DIR/partyB_ecom.csv')
data = {'identifiers': df['psi_token'].tolist()}
print(json.dumps(data))
")
    
    curl -s -X POST "http://localhost:$PSI_PORT/psi/sessions/selftest_session/upload" \
        -H "Content-Type: application/json" \
        -d "{\"party\": \"ecom\", \"data\": $ecom_psi_data}" > /dev/null
    
    # æ‰§è¡ŒPSIè®¡ç®—
    log_info "æ‰§è¡ŒPSIè®¡ç®—..."
    local psi_result=$(curl -s -X POST "http://localhost:$PSI_PORT/psi/sessions/selftest_session/compute")
    
    if echo "$psi_result" | grep -q "intersection_size"; then
        local intersection_size=$(echo "$psi_result" | python3 -c "import json, sys; print(json.load(sys.stdin)['intersection_size'])")
        log_success "PSIè®¡ç®—å®Œæˆï¼Œäº¤é›†å¤§å°: $intersection_size"
        
        # ä¿å­˜PSIç»“æœ
        echo "$psi_result" > "$REPORTS_DIR/psi_result.json"
    else
        log_error "PSIè®¡ç®—å¤±è´¥: $psi_result"
        exit 1
    fi
}

# è®­ç»ƒè”é‚¦å­¦ä¹ æ¨¡å‹
train_federated_model() {
    log_info "è®­ç»ƒè”é‚¦å­¦ä¹ æ¨¡å‹..."
    
    # æ£€æŸ¥è®­ç»ƒæœåŠ¡
    if ! check_service $TRAINER_PORT "æ¨¡å‹è®­ç»ƒ"; then
        log_error "æ¨¡å‹è®­ç»ƒæœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡"
        exit 1
    fi
    
    # æµ‹è¯•ä¸åŒçš„éšç§é¢„ç®—
    local privacy_budgets=("inf" "5" "3")
    
    for epsilon in "${privacy_budgets[@]}"; do
        log_info "è®­ç»ƒæ¨¡å‹ (Îµ=$epsilon)..."
        
        # è¿è¡Œè®­ç»ƒè„šæœ¬
        cd "$PROJECT_ROOT"
        python3 train_federated_model.py --epsilon "$epsilon" --output "$REPORTS_DIR/model_epsilon_${epsilon}.json"
        
        if [ $? -eq 0 ]; then
            log_success "æ¨¡å‹è®­ç»ƒå®Œæˆ (Îµ=$epsilon)"
        else
            log_error "æ¨¡å‹è®­ç»ƒå¤±è´¥ (Îµ=$epsilon)"
            exit 1
        fi
    done
}

# è¯„ä¼°æ¨¡å‹æ€§èƒ½
evaluate_model_performance() {
    log_info "è¯„ä¼°æ¨¡å‹æ€§èƒ½..."
    
    # åˆ›å»ºè¯„ä¼°è„šæœ¬
    cat > "$SCRIPTS_DIR/evaluate_models.py" << 'EOF'
#!/usr/bin/env python3

import json
import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve
from sklearn.calibration import calibration_curve
import seaborn as sns

def load_model_results(reports_dir):
    """åŠ è½½æ¨¡å‹ç»“æœ"""
    results = {}
    
    for file in os.listdir(reports_dir):
        if file.startswith('model_epsilon_') and file.endswith('.json'):
            epsilon = file.replace('model_epsilon_', '').replace('.json', '')
            
            with open(os.path.join(reports_dir, file), 'r') as f:
                results[epsilon] = json.load(f)
    
    return results

def calculate_ks_statistic(y_true, y_prob):
    """è®¡ç®—KSç»Ÿè®¡é‡"""
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    ks = np.max(tpr - fpr)
    return ks

def generate_performance_plots(results, output_dir):
    """ç”Ÿæˆæ€§èƒ½å›¾è¡¨"""
    plt.style.use('seaborn-v0_8')
    
    # ROCæ›²çº¿
    plt.figure(figsize=(10, 8))
    
    for epsilon, result in results.items():
        if 'predictions' in result and 'labels' in result:
            y_true = np.array(result['labels'])
            y_prob = np.array(result['predictions'])
            
            fpr, tpr, _ = roc_curve(y_true, y_prob)
            auc = roc_auc_score(y_true, y_prob)
            
            plt.plot(fpr, tpr, label=f'Îµ={epsilon} (AUC={auc:.3f})')
    
    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves for Different Privacy Budgets')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(output_dir, 'roc.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # PRæ›²çº¿
    plt.figure(figsize=(10, 8))
    
    for epsilon, result in results.items():
        if 'predictions' in result and 'labels' in result:
            y_true = np.array(result['labels'])
            y_prob = np.array(result['predictions'])
            
            precision, recall, _ = precision_recall_curve(y_true, y_prob)
            
            plt.plot(recall, precision, label=f'Îµ={epsilon}')
    
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curves')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(output_dir, 'pr.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # KSæ›²çº¿
    plt.figure(figsize=(10, 8))
    
    for epsilon, result in results.items():
        if 'predictions' in result and 'labels' in result:
            y_true = np.array(result['labels'])
            y_prob = np.array(result['predictions'])
            
            fpr, tpr, thresholds = roc_curve(y_true, y_prob)
            ks_values = tpr - fpr
            
            plt.plot(thresholds, ks_values, label=f'Îµ={epsilon}')
    
    plt.xlabel('Threshold')
    plt.ylabel('KS Statistic')
    plt.title('KS Statistics vs Threshold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(output_dir, 'ks.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("ğŸ“Š æ€§èƒ½å›¾è¡¨å·²ç”Ÿæˆ")

def generate_metrics_summary(results, output_file):
    """ç”ŸæˆæŒ‡æ ‡æ‘˜è¦"""
    metrics = {}
    
    for epsilon, result in results.items():
        if 'predictions' in result and 'labels' in result:
            y_true = np.array(result['labels'])
            y_prob = np.array(result['predictions'])
            
            auc = roc_auc_score(y_true, y_prob)
            ks = calculate_ks_statistic(y_true, y_prob)
            
            # è®¡ç®—æœ€ä¼˜é˜ˆå€¼
            fpr, tpr, thresholds = roc_curve(y_true, y_prob)
            optimal_idx = np.argmax(tpr - fpr)
            optimal_threshold = thresholds[optimal_idx]
            
            # é¢„æµ‹åˆ†å¸ƒç»Ÿè®¡
            pred_std = np.std(y_prob)
            pred_min = np.min(y_prob)
            pred_max = np.max(y_prob)
            
            metrics[epsilon] = {
                'auc': float(auc),
                'ks': float(ks),
                'optimal_threshold': float(optimal_threshold),
                'prediction_std': float(pred_std),
                'prediction_range': [float(pred_min), float(pred_max)],
                'sample_count': len(y_true),
                'positive_rate': float(np.mean(y_true))
            }
    
    with open(output_file, 'w') as f:
        json.dump(metrics, f, indent=2)
    
    print(f"ğŸ“Š æŒ‡æ ‡æ‘˜è¦å·²ä¿å­˜: {output_file}")
    return metrics

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python evaluate_models.py <reports_dir>")
        sys.exit(1)
    
    reports_dir = sys.argv[1]
    
    # åŠ è½½ç»“æœ
    results = load_model_results(reports_dir)
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹ç»“æœæ–‡ä»¶")
        sys.exit(1)
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªæ¨¡å‹ç»“æœ")
    
    # ç”Ÿæˆå›¾è¡¨
    generate_performance_plots(results, reports_dir)
    
    # ç”ŸæˆæŒ‡æ ‡æ‘˜è¦
    metrics = generate_metrics_summary(results, os.path.join(reports_dir, 'metrics.json'))
    
    # æ£€æŸ¥æ€§èƒ½è¦æ±‚
    failed_models = []
    for epsilon, metric in metrics.items():
        if metric['auc'] < 0.65 or metric['ks'] < 0.20:
            failed_models.append(epsilon)
        
        if metric['prediction_std'] < 0.01:
            print(f"âš ï¸ æ¨¡å‹ Îµ={epsilon} é¢„æµ‹åˆ†å¸ƒé€€åŒ– (std={metric['prediction_std']:.4f})")
    
    if failed_models:
        print(f"âŒ æ€§èƒ½ä¸è¾¾æ ‡çš„æ¨¡å‹: {failed_models}")
        sys.exit(1)
    else:
        print("âœ… æ‰€æœ‰æ¨¡å‹æ€§èƒ½è¾¾æ ‡")

if __name__ == '__main__':
    main()
EOF
    
    # è¿è¡Œè¯„ä¼°
    python3 "$SCRIPTS_DIR/evaluate_models.py" "$REPORTS_DIR"
    
    if [ $? -eq 0 ]; then
        log_success "æ¨¡å‹æ€§èƒ½è¯„ä¼°å®Œæˆ"
    else
        log_error "æ¨¡å‹æ€§èƒ½è¯„ä¼°å¤±è´¥"
        exit 1
    fi
}

# å¯åŠ¨æœåŠ¡å¹¶æµ‹è¯•
test_serving_api() {
    log_info "æµ‹è¯•æ¨¡å‹æœåŠ¡API..."
    
    # æ£€æŸ¥æ‰€æœ‰æœåŠ¡
    local services_ok=true
    
    if ! check_service $CONSENT_PORT "åŒæ„æœåŠ¡"; then
        services_ok=false
    fi
    
    if ! check_service $PSI_PORT "PSIæœåŠ¡"; then
        services_ok=false
    fi
    
    if ! check_service $TRAINER_PORT "è®­ç»ƒæœåŠ¡"; then
        services_ok=false
    fi
    
    if [ "$services_ok" = false ]; then
        log_error "éƒ¨åˆ†æœåŠ¡æœªè¿è¡Œï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€"
        exit 1
    fi
    
    # æµ‹è¯•è¯„åˆ†API
    log_info "æµ‹è¯•è¯„åˆ†API..."
    
    local test_data='{
        "features": {
            "debt_to_income": 0.35,
            "cc_utilization": 0.8,
            "annual_income": 50000,
            "credit_len_yrs": 5,
            "late_3m": 1,
            "delinq_12m": 2,
            "return_rate": 0.15,
            "recency_days": 30,
            "order_cnt_6m": 10,
            "monetary_6m": 1000,
            "midnight_orders_ratio": 0.1
        }
    }'
    
    local score_response=$(curl -s -X POST "http://localhost:$TRAINER_PORT/score" \
        -H "Content-Type: application/json" \
        -d "$test_data")
    
    if echo "$score_response" | grep -q "score"; then
        local score=$(echo "$score_response" | python3 -c "import json, sys; print(json.load(sys.stdin)['score'])")
        log_success "è¯„åˆ†APIæµ‹è¯•æˆåŠŸï¼Œå¾—åˆ†: $score"
        
        # æ£€æŸ¥å¾—åˆ†åˆç†æ€§
        if python3 -c "import sys; score=float('$score'); sys.exit(0 if 0 <= score <= 1 else 1)"; then
            log_success "è¯„åˆ†èŒƒå›´æ­£å¸¸ [0,1]"
        else
            log_error "è¯„åˆ†èŒƒå›´å¼‚å¸¸: $score"
            exit 1
        fi
    else
        log_error "è¯„åˆ†APIæµ‹è¯•å¤±è´¥: $score_response"
        exit 1
    fi
}

# ç”Ÿæˆè‡ªæµ‹æŠ¥å‘Š
generate_selftest_report() {
    log_info "ç”Ÿæˆè‡ªæµ‹æŠ¥å‘Š..."
    
    local report_file="$REPORTS_DIR/selftest_report.md"
    
    cat > "$report_file" << EOF
# è”é‚¦å­¦ä¹ ç³»ç»Ÿå…¨é“¾è·¯è‡ªæµ‹æŠ¥å‘Š

## æµ‹è¯•æ¦‚è§ˆ

- **æµ‹è¯•æ—¶é—´**: $(date '+%Y-%m-%d %H:%M:%S')
- **æµ‹è¯•ç¯å¢ƒ**: $(uname -s) $(uname -r)
- **Pythonç‰ˆæœ¬**: $(python3 --version)
- **Node.jsç‰ˆæœ¬**: $(node --version)

## æµ‹è¯•å‚æ•°

- **æ ·æœ¬æ•°é‡**: $SAMPLE_SIZE
- **äº¤é›†æ¯”ä¾‹**: $OVERLAP_RATIO
- **å‚ä¸æ–¹**: $PARTIES
- **éšæœºç§å­**: $SEED
- **åè´¦ç‡**: $BAD_RATE
- **å™ªå£°æ°´å¹³**: $NOISE_LEVEL

## æµ‹è¯•ç»“æœ

### 1. æ•°æ®ç”Ÿæˆä¸éªŒè¯

âœ… åˆæˆæ•°æ®ç”ŸæˆæˆåŠŸ
âœ… æ•°æ®åˆçº¦éªŒè¯é€šè¿‡

**æ•°æ®ç»Ÿè®¡**:
EOF
    
    # æ·»åŠ æ•°æ®ç»Ÿè®¡
    if [ -f "$REPORTS_DIR/data_profile.json" ]; then
        python3 -c "
import json
with open('$REPORTS_DIR/data_profile.json', 'r') as f:
    profile = json.load(f)

print('\n**æ•°æ®é›†ä¿¡æ¯**:')
for party, info in profile.get('datasets', {}).items():
    print(f'- {party}æ–¹: {info["rows"]:,} è¡Œ, {info["columns"]} åˆ—')

metrics = profile.get('quality_metrics', {})
if 'overlap_ratio' in metrics:
    print(f'- äº¤é›†æ¯”ä¾‹: {metrics["overlap_ratio"]:.3f}')
if 'bad_rate' in metrics:
    print(f'- åè´¦ç‡: {metrics["bad_rate"]:.3f}')
" >> "$report_file"
    fi
    
    cat >> "$report_file" << EOF

### 2. PSIéšç§æ±‚äº¤

âœ… PSIä¼šè¯åˆ›å»ºæˆåŠŸ
âœ… PSIè®¡ç®—å®Œæˆ

EOF
    
    # æ·»åŠ PSIç»“æœ
    if [ -f "$REPORTS_DIR/psi_result.json" ]; then
        python3 -c "
import json
with open('$REPORTS_DIR/psi_result.json', 'r') as f:
    result = json.load(f)

print(f'**äº¤é›†ç»Ÿè®¡**: {result.get("intersection_size", 0):,} ä¸ªå…±åŒæ ‡è¯†ç¬¦')
" >> "$report_file"
    fi
    
    cat >> "$report_file" << EOF

### 3. è”é‚¦å­¦ä¹ è®­ç»ƒ

âœ… å¤šéšç§é¢„ç®—è®­ç»ƒå®Œæˆ
âœ… æ¨¡å‹æ€§èƒ½è¯„ä¼°é€šè¿‡

**æ€§èƒ½æŒ‡æ ‡**:
EOF
    
    # æ·»åŠ æ€§èƒ½æŒ‡æ ‡
    if [ -f "$REPORTS_DIR/metrics.json" ]; then
        python3 -c "
import json
with open('$REPORTS_DIR/metrics.json', 'r') as f:
    metrics = json.load(f)

for epsilon, metric in metrics.items():
    print(f'\n**Îµ={epsilon}**:')
    print(f'- AUC: {metric["auc"]:.3f}')
    print(f'- KS: {metric["ks"]:.3f}')
    print(f'- æœ€ä¼˜é˜ˆå€¼: {metric["optimal_threshold"]:.3f}')
    print(f'- é¢„æµ‹æ ‡å‡†å·®: {metric["prediction_std"]:.4f}')
    print(f'- æ ·æœ¬æ•°é‡: {metric["sample_count"]:,}')
" >> "$report_file"
    fi
    
    cat >> "$report_file" << EOF

### 4. æœåŠ¡APIæµ‹è¯•

âœ… åŒæ„æœåŠ¡æ­£å¸¸
âœ… PSIæœåŠ¡æ­£å¸¸
âœ… è®­ç»ƒæœåŠ¡æ­£å¸¸
âœ… è¯„åˆ†APIæµ‹è¯•é€šè¿‡

### 5. è´¨é‡ä¿è¯

âœ… é¢„æµ‹åˆ†å¸ƒéé€€åŒ–
âœ… æ¨¡å‹æ–‡ä»¶æ­£å¸¸è½ç›˜
âœ… è¯„ä¼°æŠ¥å‘Šå®Œæ•´ç”Ÿæˆ

## ç”Ÿæˆçš„æ–‡ä»¶

- ğŸ“Š æ•°æ®æ¦‚å†µ: \`reports/data_profile.json\`
- ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡: \`reports/metrics.json\`
- ğŸ”„ PSIç»“æœ: \`reports/psi_result.json\`
- ğŸ“Š ROCæ›²çº¿: \`reports/roc.png\`
- ğŸ“Š PRæ›²çº¿: \`reports/pr.png\`
- ğŸ“Š KSæ›²çº¿: \`reports/ks.png\`
- ğŸ“‹ è‡ªæµ‹æŠ¥å‘Š: \`reports/selftest_report.md\`

## ç»“è®º

ğŸ‰ **å…¨é“¾è·¯è‡ªæµ‹é€šè¿‡!** è”é‚¦å­¦ä¹ ç³»ç»Ÿå„ç»„ä»¶è¿è¡Œæ­£å¸¸ï¼Œæ•°æ®è´¨é‡è¾¾æ ‡ï¼Œæ¨¡å‹æ€§èƒ½æ»¡è¶³è¦æ±‚ã€‚

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')*
EOF
    
    log_success "è‡ªæµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# ä¸»å‡½æ•°
main() {
    echo "ğŸš€ è”é‚¦å­¦ä¹ ç³»ç»Ÿå…¨é“¾è·¯è‡ªæµ‹"
    echo "=============================="
    
    local start_time=$(date +%s)
    
    # 1. æ£€æŸ¥ä¾èµ–
    check_dependencies
    
    # 2. é‡ç½®ç¯å¢ƒ
    reset_environment
    
    # 3. ç”Ÿæˆåˆæˆæ•°æ®
    generate_synthetic_data
    
    # 4. éªŒè¯æ•°æ®åˆçº¦
    validate_data_contract
    
    # 5. æ‰§è¡ŒPSIå¯¹é½
    perform_psi_alignment
    
    # 6. è®­ç»ƒè”é‚¦å­¦ä¹ æ¨¡å‹
    train_federated_model
    
    # 7. è¯„ä¼°æ¨¡å‹æ€§èƒ½
    evaluate_model_performance
    
    # 8. æµ‹è¯•æœåŠ¡API
    test_serving_api
    
    # 9. ç”Ÿæˆè‡ªæµ‹æŠ¥å‘Š
    generate_selftest_report
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    echo ""
    echo "=============================="
    log_success "å…¨é“¾è·¯è‡ªæµ‹å®Œæˆ! è€—æ—¶: ${duration}ç§’"
    echo "ğŸ“‹ æŸ¥çœ‹æŠ¥å‘Š: $REPORTS_DIR/selftest_report.md"
    echo "ğŸ“Š æŸ¥çœ‹å›¾è¡¨: $REPORTS_DIR/*.png"
    echo "=============================="
}

# å¤„ç†å‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        --help|-h)
            echo "è”é‚¦å­¦ä¹ ç³»ç»Ÿå…¨é“¾è·¯è‡ªæµ‹è„šæœ¬"
            echo ""
            echo "ç”¨æ³•: $0 [é€‰é¡¹]"
            echo ""
            echo "é€‰é¡¹:"
            echo "  --help, -h          æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
            echo "  --sample-size N     è®¾ç½®æ ·æœ¬æ•°é‡ (é»˜è®¤: $SAMPLE_SIZE)"
            echo "  --overlap RATIO     è®¾ç½®äº¤é›†æ¯”ä¾‹ (é»˜è®¤: $OVERLAP_RATIO)"
            echo "  --bad-rate RATE     è®¾ç½®åè´¦ç‡ (é»˜è®¤: $BAD_RATE)"
            echo "  --noise LEVEL       è®¾ç½®å™ªå£°æ°´å¹³ (é»˜è®¤: $NOISE_LEVEL)"
            echo "  --seed SEED         è®¾ç½®éšæœºç§å­ (é»˜è®¤: $SEED)"
            echo ""
            echo "ç¤ºä¾‹:"
            echo "  $0                                    # ä½¿ç”¨é»˜è®¤å‚æ•°"
            echo "  $0 --sample-size 100000 --bad-rate 0.15  # è‡ªå®šä¹‰å‚æ•°"
            exit 0
            ;;
        --sample-size)
            SAMPLE_SIZE="$2"
            shift 2
            ;;
        --overlap)
            OVERLAP_RATIO="$2"
            shift 2
            ;;
        --bad-rate)
            BAD_RATE="$2"
            shift 2
            ;;
        --noise)
            NOISE_LEVEL="$2"
            shift 2
            ;;
        --seed)
            SEED="$2"
            shift 2
            ;;
        *)
            log_error "æœªçŸ¥å‚æ•°: $1"
            echo "ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯"
            exit 1
            ;;
    esac
done

# è¿è¡Œä¸»å‡½æ•°
main