#!/usr/bin/env python3
"""
æ•°æ®åˆçº¦æ ¡éªŒå™¨
å®ç°ä¸¥æ ¼çš„æ•°æ®è´¨é‡æ£€æŸ¥ï¼Œå¤±è´¥å³åœ
"""

import argparse
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional

import numpy as np
import pandas as pd
from scipy import stats
from sklearn.metrics import roc_auc_score


class DataContractValidator:
    """æ•°æ®åˆçº¦æ ¡éªŒå™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–æ ¡éªŒå™¨
        
        Args:
            config: æ ¡éªŒé…ç½®
        """
        self.config = config or self._get_default_config()
        self.violations = []
        self.data_profile = {
            'validation_time': datetime.now().isoformat(),
            'config': self.config,
            'datasets': {},
            'violations': [],
            'quality_metrics': {},
            'recommendations': []
        }
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            # æ•°æ®å±‚æŠ¤æ 
            'min_samples': 1000,  # äº¤é›†â‰¥1000
            'max_missing_rate': 0.4,
            'max_duplicate_rate': 0.001,
            'min_overlap_ratio': 0.58,  # 0.6 Â± 0.02
            'max_overlap_ratio': 0.62,
            'min_bad_rate': 0.08,
            'max_bad_rate': 0.20,
            'min_class_ratio': 0.03,
            'min_correlation_threshold': 0.1,  # â‰¥6ä¸ªç‰¹å¾|Ï|â‰¥0.1
            'min_strong_signals': 6,
            'min_baseline_auc': 0.70,
            'max_constant_rate': 0.95,  # å¸¸é‡/NaN/Infå‰”é™¤
            'max_inf_rate': 0.01,
            'min_baseline_ks': 0.25,
            'required_bank_features': [
                'debt_to_income', 'cc_utilization', 'late_3m', 
                'delinq_12m', 'annual_income', 'credit_len_yrs'
            ],
            'required_ecom_features': [
                'return_rate', 'recency_days', 'midnight_orders_ratio',
                'order_cnt_6m', 'monetary_6m'
            ],
            'forbidden_patterns': [
                'æœªæ¥', 'future', 'æ˜¯å¦é€¾æœŸ', 'æ˜¯å¦è¿çº¦', 'æ˜¯å¦æ‹’ç»',
                'overdue_flag', 'default_flag', 'reject_flag'
            ]
        }
    
    def add_violation(self, level: str, category: str, message: str, 
                     suggestion: str = None, data: Dict = None):
        """æ·»åŠ è¿è§„è®°å½•"""
        violation = {
            'level': level,  # 'error', 'warning', 'info'
            'category': category,
            'message': message,
            'suggestion': suggestion,
            'data': data or {},
            'timestamp': datetime.now().isoformat()
        }
        self.violations.append(violation)
        self.data_profile['violations'].append(violation)
        
        # æ‰“å°è¿è§„ä¿¡æ¯
        icon = {'error': 'âŒ', 'warning': 'âš ï¸', 'info': 'â„¹ï¸'}.get(level, 'â€¢')
        print(f"{icon} [{category}] {message}")
        if suggestion:
            print(f"   ğŸ’¡ å»ºè®®: {suggestion}")
    
    def validate_structure(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯æ•°æ®ç»“æ„"""
        print("\nğŸ” éªŒè¯æ•°æ®ç»“æ„...")
        
        passed = True
        
        # æ£€æŸ¥å‚ä¸æ–¹æ•°é‡
        if len(datasets) < 2:
            self.add_violation(
                'error', 'structure', 
                f"å‚ä¸æ–¹æ•°é‡ä¸è¶³: {len(datasets)} < 2",
                "ç¡®ä¿è‡³å°‘æœ‰ä¸¤ä¸ªå‚ä¸æ–¹"
            )
            passed = False
        
        # æ£€æŸ¥äº¤é›†å¤§å°ï¼ˆæ•°æ®å±‚æŠ¤æ ï¼‰
        min_samples = min(len(df) for df in datasets.values())
        if min_samples < self.config['min_samples']:
            self.add_violation(
                'error', 'structure',
                f"äº¤é›†æ ·æœ¬æ•°ä¸è¶³: {min_samples} < {self.config['min_samples']}",
                "å¢åŠ æ•°æ®é‡æˆ–æ£€æŸ¥PSIå¯¹é½ç»“æœ"
            )
            passed = False
        
        # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        sample_counts = {party: len(df) for party, df in datasets.items()}
        if len(set(sample_counts.values())) > 1:
            self.add_violation(
                'error', 'structure',
                f"å„æ–¹æ ·æœ¬æ•°ä¸ä¸€è‡´: {sample_counts}",
                "æ£€æŸ¥PSIå¯¹é½è¿‡ç¨‹"
            )
            passed = False
        
        # æ£€æŸ¥å¿…éœ€çš„å‚ä¸æ–¹
        if 'A' not in datasets:
            self.add_violation(
                'error', 'structure',
                "ç¼ºå°‘é“¶è¡Œæ–¹(A)æ•°æ®",
                "é“¶è¡Œæ–¹æ•°æ®å¿…é¡»åŒ…å«æ ‡ç­¾åˆ—"
            )
            passed = False
        
        if 'B' not in datasets:
            self.add_violation(
                'error', 'structure',
                "ç¼ºå°‘ç”µå•†æ–¹(B)æ•°æ®",
                "ç”µå•†æ–¹æ•°æ®ç”¨äºç‰¹å¾è¡¥å……"
            )
            passed = False
        
        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        for party, df in datasets.items():
            if len(df) < self.config['min_samples']:
                self.add_violation(
                    'error', 'structure',
                    f"{party}æ–¹æ ·æœ¬æ•°é‡ä¸è¶³: {len(df)} < {self.config['min_samples']}",
                    f"å¢åŠ æ ·æœ¬æ•°é‡åˆ°è‡³å°‘ {self.config['min_samples']}"
                )
                passed = False
            
            # è®°å½•æ•°æ®é›†ä¿¡æ¯
            self.data_profile['datasets'][party] = {
                'rows': len(df),
                'columns': len(df.columns),
                'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024
            }
        
        return passed
    
    def validate_psi_tokens(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯PSIæ ‡è¯†ç¬¦"""
        print("\nğŸ” éªŒè¯PSIæ ‡è¯†ç¬¦...")
        
        passed = True
        
        # æ£€æŸ¥PSIåˆ—å­˜åœ¨æ€§
        for party, df in datasets.items():
            if 'psi_token' not in df.columns:
                self.add_violation(
                    'error', 'psi',
                    f"{party}æ–¹ç¼ºå°‘psi_tokenåˆ—",
                    "æ·»åŠ psi_tokenåˆ—ç”¨äºéšç§æ±‚äº¤"
                )
                passed = False
                continue
            
            # æ£€æŸ¥å”¯ä¸€æ€§
            unique_rate = df['psi_token'].nunique() / len(df)
            if unique_rate < 0.999:
                self.add_violation(
                    'error', 'psi',
                    f"{party}æ–¹psi_tokené‡å¤ç‡è¿‡é«˜: {1-unique_rate:.4f} > 0.001",
                    "æ£€æŸ¥PSIä»¤ç‰Œç”Ÿæˆé€»è¾‘ï¼Œç¡®ä¿å”¯ä¸€æ€§"
                )
                passed = False
            
            # æ£€æŸ¥æ ¼å¼
            if not all(isinstance(token, str) and len(token) == 64 for token in df['psi_token'].head(100)):
                self.add_violation(
                    'warning', 'psi',
                    f"{party}æ–¹psi_tokenæ ¼å¼å¼‚å¸¸",
                    "PSIä»¤ç‰Œåº”ä¸º64ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²(SHA256)"
                )
        
        # æ£€æŸ¥äº¤é›†æ¯”ä¾‹
        if 'A' in datasets and 'B' in datasets and passed:
            tokens_a = set(datasets['A']['psi_token'])
            tokens_b = set(datasets['B']['psi_token'])
            intersection = tokens_a & tokens_b
            
            overlap_ratio = len(intersection) / min(len(tokens_a), len(tokens_b))
            
            if not (self.config['min_overlap_ratio'] <= overlap_ratio <= self.config['max_overlap_ratio']):
                self.add_violation(
                    'error', 'psi',
                    f"äº¤é›†æ¯”ä¾‹å¼‚å¸¸: {overlap_ratio:.3f} ä¸åœ¨ [{self.config['min_overlap_ratio']:.2f}, {self.config['max_overlap_ratio']:.2f}] èŒƒå›´å†…",
                    "è°ƒæ•´æ•°æ®ç”Ÿæˆå‚æ•°ï¼Œç¡®ä¿åˆç†çš„äº¤é›†æ¯”ä¾‹"
                )
                passed = False
            
            self.data_profile['quality_metrics']['overlap_ratio'] = overlap_ratio
            self.data_profile['quality_metrics']['intersection_size'] = len(intersection)
        
        return passed
    
    def validate_features(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯ç‰¹å¾è´¨é‡"""
        print("\nğŸ” éªŒè¯ç‰¹å¾è´¨é‡...")
        
        passed = True
        
        for party, df in datasets.items():
            print(f"\nğŸ“Š æ£€æŸ¥ {party} æ–¹ç‰¹å¾:")
            
            # æ’é™¤PSIåˆ—å’Œæ ‡ç­¾åˆ—
            feature_cols = [col for col in df.columns 
                          if col not in ['psi_token', 'default_flag']]
            
            if len(feature_cols) == 0:
                self.add_violation(
                    'error', 'features',
                    f"{party}æ–¹æ— æœ‰æ•ˆç‰¹å¾åˆ—",
                    "æ·»åŠ ä¸šåŠ¡ç‰¹å¾åˆ—"
                )
                passed = False
                continue
            
            # æ£€æŸ¥ç¼ºå¤±ç‡
            missing_rates = df[feature_cols].isnull().mean()
            high_missing = missing_rates[missing_rates > self.config['max_missing_rate']]
            
            if len(high_missing) > 0:
                self.add_violation(
                    'error', 'features',
                    f"{party}æ–¹é«˜ç¼ºå¤±ç‡ç‰¹å¾: {dict(high_missing)}",
                    f"å¤„ç†ç¼ºå¤±å€¼æˆ–ç§»é™¤ç¼ºå¤±ç‡>{self.config['max_missing_rate']*100}%çš„ç‰¹å¾"
                )
                passed = False
            
            # æ£€æŸ¥å¸¸é‡åˆ—ï¼ˆæ•°æ®å±‚æŠ¤æ ï¼‰
            numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns
            constant_cols = []
            near_constant_cols = []
            
            for col in numeric_cols:
                if df[col].nunique() <= 1:
                    constant_cols.append(col)
                elif df[col].std() == 0:
                    constant_cols.append(col)
                else:
                    # æ£€æŸ¥è¿‘ä¼¼å¸¸é‡åˆ—ï¼ˆ95%ä»¥ä¸Šç›¸åŒå€¼ï¼‰
                    value_counts = df[col].value_counts(normalize=True)
                    if value_counts.iloc[0] > self.config['max_constant_rate']:
                        near_constant_cols.append((col, value_counts.iloc[0]))
            
            if constant_cols:
                self.add_violation(
                    'error', 'features',
                    f"{party}æ–¹å¸¸é‡åˆ—: {constant_cols}",
                    "ç§»é™¤æ— å˜åŒ–çš„ç‰¹å¾åˆ—"
                )
                passed = False
            
            if near_constant_cols:
                for col, ratio in near_constant_cols:
                    self.add_violation(
                        'warning', 'features',
                        f"{party}æ–¹è¿‘ä¼¼å¸¸é‡åˆ— {col}: {ratio:.1%}ç›¸åŒå€¼",
                        "è€ƒè™‘ç§»é™¤æˆ–é‡æ–°è®¾è®¡è¯¥ç‰¹å¾"
                    )
            
            # æ£€æŸ¥å¼‚å¸¸å€¼
            for col in numeric_cols:
                if col not in constant_cols:
                    # æ£€æŸ¥æ— ç©·å€¼ï¼ˆæ•°æ®å±‚æŠ¤æ ï¼‰
                    inf_count = np.isinf(df[col]).sum()
                    inf_rate = inf_count / len(df)
                    if inf_rate > self.config['max_inf_rate']:
                        self.add_violation(
                            'error', 'features',
                            f"{party}æ–¹ç‰¹å¾{col}æ— ç©·å€¼æ¯”ä¾‹è¿‡é«˜: {inf_rate:.1%}",
                            "å¤„ç†æ— ç©·å€¼æˆ–ç§»é™¤è¯¥ç‰¹å¾"
                        )
                        passed = False
                    elif inf_count > 0:
                        self.add_violation(
                            'warning', 'features',
                            f"{party}æ–¹ç‰¹å¾{col}åŒ…å«{inf_count}ä¸ªæ— ç©·å€¼",
                            "å»ºè®®å¤„ç†æ— ç©·å€¼"
                        )
                    
                    # æ£€æŸ¥NaNå€¼
                    nan_count = df[col].isna().sum()
                    if nan_count > len(df) * self.config['max_missing_rate']:
                        self.add_violation(
                            'warning', 'features',
                            f"{party}æ–¹ç‰¹å¾{col}ç¼ºå¤±ç‡è¿‡é«˜: {nan_count/len(df):.1%}",
                            "è€ƒè™‘ç‰¹å¾å·¥ç¨‹æˆ–ç§»é™¤è¯¥ç‰¹å¾"
                        )
            
            # æ£€æŸ¥é‡å¤æ ·æœ¬
            duplicate_rate = df.duplicated().mean()
            if duplicate_rate > self.config['max_duplicate_rate']:
                self.add_violation(
                    'error', 'features',
                    f"{party}æ–¹é‡å¤æ ·æœ¬ç‡è¿‡é«˜: {duplicate_rate:.4f} > {self.config['max_duplicate_rate']}",
                    "å»é™¤é‡å¤æ ·æœ¬"
                )
                passed = False
            
            # æ£€æŸ¥å¿…éœ€ç‰¹å¾
            required_features = {
                'A': self.config['required_bank_features'],
                'B': self.config['required_ecom_features']
            }.get(party, [])
            
            missing_required = [f for f in required_features if f not in df.columns]
            if missing_required:
                self.add_violation(
                    'error', 'features',
                    f"{party}æ–¹ç¼ºå°‘å¿…éœ€ç‰¹å¾: {missing_required}",
                    "æ·»åŠ ç¼ºå°‘çš„æ ¸å¿ƒä¸šåŠ¡ç‰¹å¾"
                )
                passed = False
        
        return passed
    
    def validate_labels(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯æ ‡ç­¾è´¨é‡"""
        print("\nğŸ” éªŒè¯æ ‡ç­¾è´¨é‡...")
        
        passed = True
        
        if 'A' not in datasets:
            return passed
        
        df = datasets['A']
        
        # æ£€æŸ¥æ ‡ç­¾åˆ—å­˜åœ¨æ€§
        if 'default_flag' not in df.columns:
            self.add_violation(
                'error', 'labels',
                "é“¶è¡Œæ–¹ç¼ºå°‘default_flagæ ‡ç­¾åˆ—",
                "æ·»åŠ äºŒåˆ†ç±»æ ‡ç­¾åˆ—"
            )
            return False
        
        labels = df['default_flag']
        
        # æ£€æŸ¥æ ‡ç­¾ç±»å‹
        unique_labels = labels.unique()
        if not set(unique_labels).issubset({0, 1}):
            self.add_violation(
                'error', 'labels',
                f"æ ‡ç­¾å€¼å¼‚å¸¸: {unique_labels}ï¼Œåº”ä¸º0/1",
                "ç¡®ä¿æ ‡ç­¾ä¸ºäºŒåˆ†ç±»(0/1)"
            )
            passed = False
        
        # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒï¼ˆæ•°æ®å±‚æŠ¤æ ï¼šæ ‡ç­¾ä¸¤ç±»å­˜åœ¨ï¼‰
        if len(unique_labels) < 2:
            self.add_violation(
                'error', 'labels',
                f"æ ‡ç­¾ç±»åˆ«ä¸è¶³: {len(unique_labels)} < 2",
                "ç¡®ä¿æ­£è´Ÿæ ·æœ¬éƒ½å­˜åœ¨"
            )
            passed = False
        
        # æ£€æŸ¥æ ‡ç­¾ç¼ºå¤±
        missing_labels = labels.isnull().sum()
        if missing_labels > 0:
            self.add_violation(
                'error', 'labels',
                f"æ ‡ç­¾å­˜åœ¨{missing_labels}ä¸ªç¼ºå¤±å€¼",
                "å¤„ç†æ ‡ç­¾ç¼ºå¤±å€¼"
            )
            passed = False
        
        # æ£€æŸ¥ç±»åˆ«å¹³è¡¡ï¼ˆæ•°æ®å±‚æŠ¤æ ï¼šbad_rateâˆˆ[0.08,0.20]ï¼‰
        bad_rate = labels.mean()
        if not (self.config['min_bad_rate'] <= bad_rate <= self.config['max_bad_rate']):
            self.add_violation(
                'error', 'labels',
                f"åè´¦ç‡å¼‚å¸¸: {bad_rate:.3f} ä¸åœ¨ [{self.config['min_bad_rate']:.2f}, {self.config['max_bad_rate']:.2f}] èŒƒå›´å†…",
                "è°ƒæ•´æ ‡ç­¾ç”Ÿæˆé€»è¾‘æˆ–é‡æ–°é‡‡æ ·"
            )
            passed = False
            
        # è®°å½•è¯¦ç»†æ ‡ç­¾ç»Ÿè®¡
        positive_count = int(labels.sum())
        negative_count = int((1 - labels).sum())
        print(f"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: æ­£æ ·æœ¬ {positive_count} ({bad_rate:.1%}), è´Ÿæ ·æœ¬ {negative_count} ({1-bad_rate:.1%})")
        
        # æ£€æŸ¥æœ€å°ç±»åˆ«æ¯”ä¾‹
        min_class_ratio = min(bad_rate, 1 - bad_rate)
        if min_class_ratio < self.config['min_class_ratio']:
            self.add_violation(
                'error', 'labels',
                f"æœ€å°ç±»åˆ«æ¯”ä¾‹è¿‡ä½: {min_class_ratio:.3f} < {self.config['min_class_ratio']}",
                "å¢åŠ å°‘æ•°ç±»æ ·æœ¬æˆ–å¯ç”¨é‡åŠ æƒ"
            )
            passed = False
        
        self.data_profile['quality_metrics']['bad_rate'] = bad_rate
        self.data_profile['quality_metrics']['label_distribution'] = {
            'positive': int(labels.sum()),
            'negative': int((1 - labels).sum())
        }
        
        return passed
    
    def validate_data_leakage(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯æ•°æ®æ³„æ¼"""
        print("\nğŸ” éªŒè¯æ•°æ®æ³„æ¼...")
        
        passed = True
        
        for party, df in datasets.items():
            # æ£€æŸ¥åˆ—åä¸­çš„æ³„æ¼æ¨¡å¼
            for col in df.columns:
                col_lower = col.lower()
                for pattern in self.config['forbidden_patterns']:
                    if pattern.lower() in col_lower:
                        self.add_violation(
                            'error', 'leakage',
                            f"{party}æ–¹ç‰¹å¾'{col}'å¯èƒ½åŒ…å«æœªæ¥ä¿¡æ¯",
                            f"ç§»é™¤æˆ–é‡å‘½ååŒ…å«'{pattern}'çš„ç‰¹å¾"
                        )
                        passed = False
            
            # æ£€æŸ¥æ—¶é—´ç›¸å…³ç‰¹å¾
            time_related_cols = [col for col in df.columns 
                               if any(keyword in col.lower() 
                                    for keyword in ['date', 'time', 'day', 'month', 'year'])]
            
            if time_related_cols:
                self.add_violation(
                    'warning', 'leakage',
                    f"{party}æ–¹åŒ…å«æ—¶é—´ç›¸å…³ç‰¹å¾: {time_related_cols}",
                    "ç¡®è®¤æ—¶é—´ç‰¹å¾ä¸åŒ…å«æœªæ¥ä¿¡æ¯"
                )
        
        return passed
    
    def validate_signal_strength(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯ä¿¡å·å¼ºåº¦"""
        print("\nğŸ” éªŒè¯ä¿¡å·å¼ºåº¦...")
        
        passed = True
        
        if 'A' not in datasets or 'default_flag' not in datasets['A'].columns:
            return passed
        
        labels = datasets['A']['default_flag']
        correlations = {}
        
        # è®¡ç®—å„æ–¹ç‰¹å¾ä¸æ ‡ç­¾çš„ç›¸å…³æ€§
        for party, df in datasets.items():
            feature_cols = [col for col in df.columns 
                          if col not in ['psi_token', 'default_flag']]
            numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                try:
                    # è®¡ç®—ç‚¹åŒåˆ—ç›¸å…³ç³»æ•°
                    corr = np.corrcoef(df[col].fillna(df[col].median()), labels)[0, 1]
                    if not np.isnan(corr):
                        correlations[f'{party}_{col}'] = abs(corr)
                except:
                    continue
        
        # æ£€æŸ¥å¼ºä¿¡å·æ•°é‡ï¼ˆæ•°æ®å±‚æŠ¤æ ï¼šâ‰¥6ä¸ªç‰¹å¾|Ï|â‰¥0.1ï¼‰
        strong_signals = {k: v for k, v in correlations.items() 
                         if v >= self.config['min_correlation_threshold']}
        
        if len(strong_signals) < self.config['min_strong_signals']:
            self.add_violation(
                'error', 'signal',
                f"å¼ºä¿¡å·ç‰¹å¾ä¸è¶³: {len(strong_signals)}/{self.config['min_strong_signals']}",
                "å¢åŠ ä¸æ ‡ç­¾ç›¸å…³çš„ç‰¹å¾æˆ–è°ƒæ•´ç‰¹å¾å·¥ç¨‹"
            )
            passed = False
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿‡å¼ºä¿¡å·ï¼ˆå¯èƒ½æ•°æ®æ³„éœ²ï¼‰
        very_strong_signals = {k: v for k, v in correlations.items() if v > 0.8}
        if very_strong_signals:
            self.add_violation(
                'warning', 'signal',
                f"å‘ç°è¿‡å¼ºä¿¡å·ç‰¹å¾: {very_strong_signals}",
                "æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®æ³„éœ²"
            )
        
        # è®°å½•ç›¸å…³æ€§ä¿¡æ¯
        self.data_profile['quality_metrics']['feature_correlations'] = correlations
        self.data_profile['quality_metrics']['strong_signals'] = strong_signals
        
        print(f"ğŸ“ˆ å¼ºä¿¡å·ç‰¹å¾: {len(strong_signals)}/{self.config['min_strong_signals']}")
        for feature, corr in sorted(strong_signals.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  {feature}: {corr:.3f}")
        
        return passed
    
    def validate_baseline_performance(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """éªŒè¯åŸºçº¿æ€§èƒ½"""
        print("\nğŸ” éªŒè¯åŸºçº¿æ€§èƒ½...")
        
        passed = True
        
        if 'A' not in datasets or 'B' not in datasets:
            return passed
        
        if 'default_flag' not in datasets['A'].columns:
            return passed
        
        try:
            from sklearn.linear_model import LogisticRegression
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import StandardScaler
            from sklearn.metrics import roc_auc_score
            
            # å‡†å¤‡æ•°æ®
            bank_features = datasets['A'].select_dtypes(include=[np.number]).drop(columns=['default_flag'], errors='ignore')
            ecom_features = datasets['B'].select_dtypes(include=[np.number])
            
            # åˆå¹¶ç‰¹å¾
            features = pd.concat([bank_features, ecom_features], axis=1)
            features = features.fillna(features.median())
            
            labels = datasets['A']['default_flag']
            
            # åˆ†å‰²æ•°æ®
            X_train, X_test, y_train, y_test = train_test_split(
                features, labels, test_size=0.3, random_state=42, stratify=labels
            )
            
            # æ ‡å‡†åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # è®­ç»ƒé€»è¾‘å›å½’
            lr = LogisticRegression(random_state=42, max_iter=1000)
            lr.fit(X_train_scaled, y_train)
            
            # é¢„æµ‹
            y_pred_proba = lr.predict_proba(X_test_scaled)[:, 1]
            
            # è®¡ç®—AUC
            auc = roc_auc_score(y_test, y_pred_proba)
            
            # è®¡ç®—KS
            def calculate_ks(y_true, y_prob):
                from scipy.stats import ks_2samp
                pos_scores = y_prob[y_true == 1]
                neg_scores = y_prob[y_true == 0]
                return ks_2samp(pos_scores, neg_scores).statistic
            
            ks = calculate_ks(y_test, y_pred_proba)
            
            # æ£€æŸ¥æ€§èƒ½è¦æ±‚
            if auc < self.config['min_baseline_auc']:
                self.add_violation(
                    'error', 'performance',
                    f"åŸºçº¿AUCä¸è¾¾æ ‡: {auc:.3f} < {self.config['min_baseline_auc']}",
                    "å¢å¼ºç‰¹å¾å·¥ç¨‹æˆ–è°ƒæ•´æ•°æ®ç”Ÿæˆé€»è¾‘"
                )
                passed = False
            
            if ks < self.config['min_baseline_ks']:
                self.add_violation(
                    'error', 'performance',
                    f"åŸºçº¿KSä¸è¾¾æ ‡: {ks:.3f} < {self.config['min_baseline_ks']}",
                    "å¢å¼ºç‰¹å¾åŒºåˆ†åº¦æˆ–è°ƒæ•´æ ‡ç­¾ç”Ÿæˆ"
                )
                passed = False
            
            self.data_profile['quality_metrics']['baseline_performance'] = {
                'auc': auc,
                'ks': ks,
                'feature_count': len(features.columns)
            }
            
            print(f"ğŸ“Š åŸºçº¿æ€§èƒ½ - AUC: {auc:.3f}, KS: {ks:.3f}")
            
        except Exception as e:
            self.add_violation(
                'warning', 'performance',
                f"åŸºçº¿æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}",
                "æ£€æŸ¥æ•°æ®æ ¼å¼å’Œä¾èµ–åº“"
            )
        
        return passed
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        recommendations = []
        
        # æŒ‰è¿è§„ç±»åˆ«åˆ†ç»„
        error_violations = [v for v in self.violations if v['level'] == 'error']
        
        if error_violations:
            recommendations.append("ğŸš¨ ä¸¥é‡é—®é¢˜éœ€è¦ç«‹å³ä¿®å¤:")
            
            # ç»“æ„é—®é¢˜
            structure_errors = [v for v in error_violations if v['category'] == 'structure']
            if structure_errors:
                recommendations.append("  ğŸ“ æ•°æ®ç»“æ„é—®é¢˜:")
                for v in structure_errors:
                    recommendations.append(f"    - {v['message']}")
                    if v['suggestion']:
                        recommendations.append(f"      ğŸ’¡ {v['suggestion']}")
            
            # PSIé—®é¢˜
            psi_errors = [v for v in error_violations if v['category'] == 'psi']
            if psi_errors:
                recommendations.append("  ğŸ”— PSIæ ‡è¯†ç¬¦é—®é¢˜:")
                for v in psi_errors:
                    recommendations.append(f"    - {v['message']}")
                    if v['suggestion']:
                        recommendations.append(f"      ğŸ’¡ {v['suggestion']}")
            
            # ç‰¹å¾é—®é¢˜
            feature_errors = [v for v in error_violations if v['category'] == 'features']
            if feature_errors:
                recommendations.append("  ğŸ“Š ç‰¹å¾è´¨é‡é—®é¢˜:")
                for v in feature_errors:
                    recommendations.append(f"    - {v['message']}")
                    if v['suggestion']:
                        recommendations.append(f"      ğŸ’¡ {v['suggestion']}")
            
            # æ ‡ç­¾é—®é¢˜
            label_errors = [v for v in error_violations if v['category'] == 'labels']
            if label_errors:
                recommendations.append("  ğŸ¯ æ ‡ç­¾è´¨é‡é—®é¢˜:")
                for v in label_errors:
                    recommendations.append(f"    - {v['message']}")
                    if v['suggestion']:
                        recommendations.append(f"      ğŸ’¡ {v['suggestion']}")
            
            # ä¿¡å·å¼ºåº¦é—®é¢˜
            signal_errors = [v for v in error_violations if v['category'] == 'signal']
            if signal_errors:
                recommendations.append("  ğŸ“ˆ ä¿¡å·å¼ºåº¦é—®é¢˜:")
                for v in signal_errors:
                    recommendations.append(f"    - {v['message']}")
                    if v['suggestion']:
                        recommendations.append(f"      ğŸ’¡ {v['suggestion']}")
            
            # æ€§èƒ½é—®é¢˜
            perf_errors = [v for v in error_violations if v['category'] == 'performance']
            if perf_errors:
                recommendations.append("  ğŸ¯ æ€§èƒ½é—®é¢˜:")
                for v in perf_errors:
                    recommendations.append(f"    - {v['message']}")
                    if v['suggestion']:
                        recommendations.append(f"      ğŸ’¡ {v['suggestion']}")
        
        # é€šç”¨å»ºè®®
        if error_violations:
            recommendations.extend([
                "",
                "ğŸ”§ é€šç”¨ä¿®å¤æ­¥éª¤:",
                "  1. é‡æ–°ç”Ÿæˆæ•°æ®: python tools/seed/synth_vertical_v2.py --n 50000 --bad_rate 0.12",
                "  2. è°ƒæ•´ç”Ÿæˆå‚æ•°: ä¿®æ”¹ --overlap, --noise, --seed å‚æ•°",
                "  3. æ£€æŸ¥ç‰¹å¾å·¥ç¨‹: ç¡®ä¿ç‰¹å¾ä¸ä¸šåŠ¡é€»è¾‘ä¸€è‡´",
                "  4. éªŒè¯æ•°æ®è´¨é‡: python tools/contract/data_contract.py --files *.csv"
            ])
        
        self.data_profile['recommendations'] = recommendations
        return recommendations
    
    def apply_data_guards(self, datasets: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:
        """åº”ç”¨æ•°æ®å±‚æŠ¤æ ï¼Œè‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜"""
        print("\nğŸ›¡ï¸ åº”ç”¨æ•°æ®å±‚æŠ¤æ ...")
        
        cleaned_datasets = {}
        
        for party, df in datasets.items():
            cleaned_df = df.copy()
            
            # ç§»é™¤å¸¸é‡åˆ—
            feature_cols = [col for col in cleaned_df.columns 
                          if col not in ['psi_token', 'default_flag']]
            numeric_cols = cleaned_df[feature_cols].select_dtypes(include=[np.number]).columns
            
            constant_cols = []
            for col in numeric_cols:
                if cleaned_df[col].nunique() <= 1 or cleaned_df[col].std() == 0:
                    constant_cols.append(col)
            
            if constant_cols:
                cleaned_df = cleaned_df.drop(columns=constant_cols)
                print(f"ğŸ§¹ {party}æ–¹ç§»é™¤å¸¸é‡åˆ—: {constant_cols}")
            
            # å¤„ç†æ— ç©·å€¼
            for col in numeric_cols:
                if col in cleaned_df.columns:
                    inf_mask = np.isinf(cleaned_df[col])
                    if inf_mask.any():
                        # ç”¨ä¸­ä½æ•°æ›¿æ¢æ— ç©·å€¼
                        median_val = cleaned_df[col][~inf_mask].median()
                        cleaned_df.loc[inf_mask, col] = median_val
                        print(f"ğŸ”§ {party}æ–¹ç‰¹å¾{col}çš„{inf_mask.sum()}ä¸ªæ— ç©·å€¼å·²æ›¿æ¢ä¸ºä¸­ä½æ•°")
            
            # å¤„ç†NaNå€¼
            for col in numeric_cols:
                if col in cleaned_df.columns:
                    nan_count = cleaned_df[col].isnull().sum()
                    if nan_count > 0:
                        median_val = cleaned_df[col].median()
                        cleaned_df[col].fillna(median_val, inplace=True)
                        print(f"ğŸ”§ {party}æ–¹ç‰¹å¾{col}çš„{nan_count}ä¸ªç¼ºå¤±å€¼å·²å¡«å……")
            
            cleaned_datasets[party] = cleaned_df
        
        return cleaned_datasets
    
    def validate(self, datasets: Dict[str, pd.DataFrame]) -> bool:
        """æ‰§è¡Œå®Œæ•´éªŒè¯"""
        print(f"ğŸš€ å¼€å§‹æ•°æ®åˆçº¦éªŒè¯...")
        print(f"ğŸ“Š æ•°æ®é›†: {list(datasets.keys())}")
        
        # åº”ç”¨æ•°æ®å±‚æŠ¤æ 
        cleaned_datasets = self.apply_data_guards(datasets)
        
        all_passed = True
        
        # 1. ç»“æ„éªŒè¯
        if not self.validate_structure(cleaned_datasets):
            all_passed = False
        
        # 2. PSIæ ‡è¯†ç¬¦éªŒè¯
        if not self.validate_psi_tokens(cleaned_datasets):
            all_passed = False
        
        # 3. ç‰¹å¾è´¨é‡éªŒè¯
        if not self.validate_features(cleaned_datasets):
            all_passed = False
        
        # 4. æ ‡ç­¾è´¨é‡éªŒè¯
        if not self.validate_labels(cleaned_datasets):
            all_passed = False
        
        # 5. æ•°æ®æ³„æ¼éªŒè¯
        if not self.validate_data_leakage(cleaned_datasets):
            all_passed = False
        
        # 6. ä¿¡å·å¼ºåº¦éªŒè¯
        if not self.validate_signal_strength(cleaned_datasets):
            all_passed = False
        
        # 7. åŸºçº¿æ€§èƒ½éªŒè¯
        if not self.validate_baseline_performance(cleaned_datasets):
            all_passed = False
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self.generate_recommendations()
        
        # è¾“å‡ºç»“æœ
        print(f"\n{'='*60}")
        if all_passed:
            print("âœ… æ•°æ®åˆçº¦éªŒè¯é€šè¿‡!")
        else:
            print("âŒ æ•°æ®åˆçº¦éªŒè¯å¤±è´¥!")
            print(f"\nğŸ“‹ ä¿®å¤å»ºè®®:")
            for rec in recommendations:
                print(rec)
            
            # å¦‚æœæœ‰é”™è¯¯ï¼Œç›´æ¥ä¸­æ­¢å¹¶ç»™å‡ºä¿®å¤å»ºè®®
            error_count = len([v for v in self.violations if v['level'] == 'error'])
            if error_count > 0:
                print("\nğŸ›‘ å‘ç°ä¸¥é‡é”™è¯¯ï¼Œè®­ç»ƒä¸­æ­¢")
                print("\nğŸ“‹ ä¿®å¤å»ºè®®:")
                for violation in self.violations:
                    if violation['level'] == 'error' and violation['suggestion']:
                        print(f"  â€¢ {violation['suggestion']}")
        
        print(f"\nğŸ“Š éªŒè¯ç»Ÿè®¡:")
        error_count = len([v for v in self.violations if v['level'] == 'error'])
        warning_count = len([v for v in self.violations if v['level'] == 'warning'])
        print(f"  é”™è¯¯: {error_count}")
        print(f"  è­¦å‘Š: {warning_count}")
        print(f"  æ€»è®¡: {len(self.violations)}")
        
        return all_passed
    
    def save_profile(self, output_path: str):
        """ä¿å­˜æ•°æ®æ¦‚å†µ"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.data_profile, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“Š æ•°æ®æ¦‚å†µå·²ä¿å­˜: {output_path}")


def load_datasets(file_paths: List[str]) -> Dict[str, pd.DataFrame]:
    """åŠ è½½æ•°æ®é›†"""
    datasets = {}
    
    for file_path in file_paths:
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        try:
            # æ ¹æ®æ–‡ä»¶åæ¨æ–­å‚ä¸æ–¹
            filename = os.path.basename(file_path).lower()
            if 'bank' in filename or 'partya' in filename:
                party = 'A'
            elif 'ecom' in filename or 'partyb' in filename:
                party = 'B'
            elif 'telco' in filename or 'partyc' in filename:
                party = 'C'
            else:
                party = filename.split('.')[0].upper()
            
            # åŠ è½½æ•°æ®
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path)
            elif file_path.endswith('.json'):
                df = pd.read_json(file_path)
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
                continue
            
            datasets[party] = df
            print(f"ğŸ“ å·²åŠ è½½ {party} æ–¹æ•°æ®: {file_path} ({len(df)} è¡Œ, {len(df.columns)} åˆ—)")
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    return datasets


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®åˆçº¦æ ¡éªŒå™¨')
    parser.add_argument('--files', nargs='+', required=True, help='æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default='data_profile.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--strict', action='store_true', help='ä¸¥æ ¼æ¨¡å¼ï¼Œä»»ä½•é”™è¯¯éƒ½è¿”å›å¤±è´¥')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = None
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)
    
    # åŠ è½½æ•°æ®é›†
    datasets = load_datasets(args.files)
    
    if not datasets:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®é›†")
        sys.exit(1)
    
    # æ‰§è¡ŒéªŒè¯
    validator = DataContractValidator(config)
    success = validator.validate(datasets)
    
    # ä¿å­˜ç»“æœ
    validator.save_profile(args.output)
    
    # è¿”å›ç»“æœ
    if success:
        print(f"\nğŸ‰ æ•°æ®åˆçº¦éªŒè¯æˆåŠŸ!")
        sys.exit(0)
    else:
        print(f"\nğŸ’¥ æ•°æ®åˆçº¦éªŒè¯å¤±è´¥!")
        if args.strict:
            sys.exit(1)
        else:
            print("âš ï¸ éä¸¥æ ¼æ¨¡å¼ï¼Œç»§ç»­æ‰§è¡Œ")
            sys.exit(0)


if __name__ == '__main__':
    main()