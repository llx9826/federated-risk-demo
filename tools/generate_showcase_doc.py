#!/usr/bin/env python3
"""
å±•ç¤ºæ–‡æ¡£ç”Ÿæˆå™¨

åŸºäºåŸºå‡†æµ‹è¯•ç»“æœç”Ÿæˆå®Œæ•´çš„å±•ç¤ºæ–‡æ¡£
"""

import json
import os
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
from loguru import logger

class ShowcaseDocGenerator:
    """å±•ç¤ºæ–‡æ¡£ç”Ÿæˆå™¨"""
    
    def __init__(self, project_root: str = "."):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.project_root = Path(project_root)
        self.reports_dir = self.project_root / "reports"
        self.assets_dir = self.project_root / "docs" / "assets"
        self.docs_dir = self.project_root / "docs"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.assets_dir.mkdir(parents=True, exist_ok=True)
        self.docs_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"åˆå§‹åŒ–å±•ç¤ºæ–‡æ¡£ç”Ÿæˆå™¨: {self.project_root}")
        logger.info(f"æŠ¥å‘Šç›®å½•: {self.reports_dir}")
        logger.info(f"èµ„æºç›®å½•: {self.assets_dir}")
        logger.info(f"æ–‡æ¡£ç›®å½•: {self.docs_dir}")
    
    def load_test_results(self) -> Dict:
        """åŠ è½½æµ‹è¯•ç»“æœæ•°æ®"""
        logger.info("åŠ è½½æµ‹è¯•ç»“æœæ•°æ®...")
        
        results = {
            'psi_summary': None,
            'train_summary': None,
            'psi_results': [],
            'train_results': []
        }
        
        # åŠ è½½PSIæ±‡æ€»æ•°æ®
        psi_summary_file = self.reports_dir / "psi_summary.csv"
        if psi_summary_file.exists():
            results['psi_summary'] = pd.read_csv(psi_summary_file)
            logger.info(f"âœ“ åŠ è½½PSIæ±‡æ€»æ•°æ®: {len(results['psi_summary'])} æ¡è®°å½•")
        
        # åŠ è½½è®­ç»ƒæ±‡æ€»æ•°æ®
        train_summary_file = self.reports_dir / "train" / "train_summary.csv"
        if not train_summary_file.exists():
            train_summary_file = self.project_root / "bench" / "train-bench" / "data" / "train_results" / "train_summary.csv"
        
        if train_summary_file.exists():
            results['train_summary'] = pd.read_csv(train_summary_file)
            logger.info(f"âœ“ åŠ è½½è®­ç»ƒæ±‡æ€»æ•°æ®: {len(results['train_summary'])} æ¡è®°å½•")
        
        return results
    
    def validate_assets(self) -> Dict[str, bool]:
        """éªŒè¯å›¾ç‰‡èµ„æº"""
        logger.info("éªŒè¯å›¾ç‰‡èµ„æº...")
        
        required_assets = [
            "psi_throughput.png",
            "psi_latency.png",
            "train_auc_ks_vs_epsilon.png",
            "train_comm_vs_round.png",
            "inference_latency.png",
            "improvement_before_after.png"
        ]
        
        asset_status = {}
        for asset in required_assets:
            asset_file = self.assets_dir / asset
            asset_status[asset] = asset_file.exists()
            if asset_status[asset]:
                logger.info(f"âœ“ {asset}")
            else:
                logger.warning(f"âœ— {asset} ä¸å­˜åœ¨")
        
        return asset_status
    
    def generate_file_manifest(self) -> Dict[str, str]:
        """ç”Ÿæˆæ–‡ä»¶æ¸…å•å’ŒSHA256æ‘˜è¦"""
        logger.info("ç”Ÿæˆæ–‡ä»¶æ¸…å•...")
        
        manifest = {}
        
        # æ‰«æreportsç›®å½•
        if self.reports_dir.exists():
            for file_path in self.reports_dir.rglob("*"):
                if file_path.is_file() and file_path.suffix in ['.csv', '.jsonl', '.json']:
                    try:
                        with open(file_path, 'rb') as f:
                            content = f.read()
                            sha256_hash = hashlib.sha256(content).hexdigest()
                            relative_path = file_path.relative_to(self.project_root)
                            manifest[str(relative_path)] = sha256_hash
                    except Exception as e:
                        logger.warning(f"æ— æ³•è®¡ç®— {file_path} çš„SHA256: {e}")
        
        logger.info(f"ç”Ÿæˆæ–‡ä»¶æ¸…å•: {len(manifest)} ä¸ªæ–‡ä»¶")
        return manifest
    
    def format_number(self, num: float, precision: int = 2) -> str:
        """æ ¼å¼åŒ–æ•°å­—æ˜¾ç¤º"""
        if num >= 1e9:
            return f"{num/1e9:.{precision}f}B"
        elif num >= 1e6:
            return f"{num/1e6:.{precision}f}M"
        elif num >= 1e3:
            return f"{num/1e3:.{precision}f}K"
        else:
            return f"{num:.{precision}f}"
    
    def generate_psi_summary_table(self, psi_summary: pd.DataFrame) -> str:
        """ç”ŸæˆPSIæ±‡æ€»è¡¨æ ¼"""
        if psi_summary is None or len(psi_summary) == 0:
            return "| æµ‹è¯•ID | æ•°æ®è§„æ¨¡ | å®Œæˆæ—¶é—´ | ååé‡ |\n|--------|----------|----------|--------|\n| æš‚æ— æ•°æ® | - | - | - |"
        
        table = "| æµ‹è¯•ID | æ•°æ®è§„æ¨¡ | å®Œæˆæ—¶é—´ | ååé‡ |\n"
        table += "|--------|----------|----------|--------|\n"
        
        for _, row in psi_summary.iterrows():
            test_id = row.get('test_id', 'N/A')
            total_processed = self.format_number(row.get('total_processed', 0))
            wall_clock_hours = f"{row.get('wall_clock_hours', 0):.2f}h"
            throughput = self.format_number(row.get('throughput_per_hour', 0))
            
            table += f"| {test_id} | {total_processed} | {wall_clock_hours} | {throughput}/h |\n"
        
        table += "\n**æŠ€æœ¯ç‰¹æ€§**:\n"
        table += "| ç‰¹æ€§ | å®ç°æ–¹æ¡ˆ |\n"
        table += "|------|----------|\n"
        table += "| ç®—æ³• | ECDH-PSI (æ¤­åœ†æ›²çº¿P-256) |\n"
        table += "| åˆ†ç‰‡ç­–ç•¥ | Rayåˆ†å¸ƒå¼å¹¶è¡Œ |"
        
        return table
    
    def generate_train_summary_table(self, train_summary: pd.DataFrame) -> str:
        """ç”Ÿæˆè®­ç»ƒæ±‡æ€»è¡¨æ ¼"""
        if train_summary is None or len(train_summary) == 0:
            return "| æµ‹è¯•ID | æ ·æœ¬æ•° | è½®æ¬¡ | AUC | KS | å®Œæˆæ—¶é—´ |\n|--------|--------|------|-----|----|---------|"
        
        table = "| æµ‹è¯•ID | æ ·æœ¬æ•° | è½®æ¬¡ | AUC | KS | å®Œæˆæ—¶é—´ |\n"
        table += "|--------|--------|------|-----|----|---------|"
        
        for _, row in train_summary.iterrows():
            test_id = row.get('test_id', 'N/A')
            n_samples = self.format_number(row.get('n_samples', 0))
            total_rounds = row.get('total_rounds', 0)
            final_auc = f"{row.get('final_auc', 0):.4f}"
            final_ks = f"{row.get('final_ks', 0):.4f}"
            wall_clock_hours = f"{row.get('wall_clock_hours', 0):.2f}h"
            
            table += f"\n| {test_id} | {n_samples} | {total_rounds} | {final_auc} | {final_ks} | {wall_clock_hours} |"
        
        table += "\n\n**æŠ€æœ¯ç‰¹æ€§**:\n"
        table += "| ç‰¹æ€§ | å®ç°æ–¹æ¡ˆ |\n"
        table += "|------|----------|\n"
        table += "| ç®—æ³• | SecureBoost (Fed-XGBoost) |\n"
        table += "| éšç§ä¿æŠ¤ | å·®åˆ†éšç§ + æ¢¯åº¦é‡åŒ– |"
        
        return table
    
    def generate_showcase_document(self, results: Dict, asset_status: Dict[str, bool], 
                                 manifest: Dict[str, str]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„å±•ç¤ºæ–‡æ¡£"""
        logger.info("ç”Ÿæˆå±•ç¤ºæ–‡æ¡£...")
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # æ„å»ºæ–‡æ¡£å†…å®¹
        doc_content = "# å¹³å®‰é“¶è¡Œè”é‚¦å­¦ä¹ åŸºå‡†æµ‹è¯•å±•ç¤ºæŠ¥å‘Š\n\n"
        doc_content += "[TOC]\n\n"
        
        # é¡¹ç›®æ€»è§ˆ
        doc_content += "## 1. é¡¹ç›®æ€»è§ˆ\n\n"
        doc_content += "å¹³å®‰é“¶è¡Œ\"æˆæƒå‰ç½®-PSIå¯¹é½-è”é‚¦å»ºæ¨¡-è§£é‡Šä¸Šçº¿-å®¡è®¡åˆè§„\"çš„å…­æ­¥é—­ç¯ï¼Œå®ç°ä¿¡ç”¨å¡ã€æ¶ˆé‡‘ã€æ±½èç­‰åœºæ™¯çš„éšç§ä¿æŠ¤è”åˆå»ºæ¨¡ã€‚\n\n"
        
        doc_content += "### 1.1 æ ¸å¿ƒäº®ç‚¹\n\n"
        doc_content += "| ç‰¹æ€§ | æè¿° | æŠ€æœ¯å®ç° |\n"
        doc_content += "|------|------|----------|\n"
        doc_content += "| ç›®çš„ç»‘å®šåŒæ„ | Purpose-Bound Consentæœºåˆ¶ | JWT + ä¸šåŠ¡åœºæ™¯æ ‡è¯† |\n"
        doc_content += "| é›¶æ˜æ–‡å¯¹é½ | éšç§é›†åˆæ±‚äº¤(PSI) | ECDH-PSI + Bloomè¿‡æ»¤ |\n"
        doc_content += "| å®‰å…¨èšåˆ | å·®åˆ†éšç§ä¿æŠ¤ | SecAgg + é«˜æ–¯å™ªå£° |\n"
        doc_content += "| è”é‚¦è§£é‡Š | æ¨¡å‹å¯è§£é‡Šæ€§ | SHAP + ç‰¹å¾é‡è¦æ€§ |\n"
        doc_content += "| å…¨é“¾è·¯å®¡è®¡ | ç«¯åˆ°ç«¯å¯è¿½æº¯ | ç»“æ„åŒ–æ—¥å¿— + å®Œæ•´æ€§æ ¡éªŒ |\n\n"
        
        # PSIåŸºå‡†æµ‹è¯•ç»“æœ
        doc_content += "## 2. PSIåŸºå‡†æµ‹è¯•ç»“æœ\n\n"
        doc_content += "### 2.1 æµ‹è¯•æ¦‚è§ˆ\n\n"
        doc_content += self.generate_psi_summary_table(results['psi_summary'])
        doc_content += "\n\n"
        
        if asset_status.get('psi_throughput.png', False):
            doc_content += "![PSIååé‡](assets/psi_throughput.png)\n\n"
        
        if asset_status.get('psi_latency.png', False):
            doc_content += "![PSIå»¶è¿Ÿåˆ†å¸ƒ](assets/psi_latency.png)\n\n"
        
        # è”é‚¦è®­ç»ƒåŸºå‡†æµ‹è¯•ç»“æœ
        doc_content += "## 3. è”é‚¦è®­ç»ƒåŸºå‡†æµ‹è¯•ç»“æœ\n\n"
        doc_content += "### 3.1 æµ‹è¯•æ¦‚è§ˆ\n\n"
        doc_content += self.generate_train_summary_table(results['train_summary'])
        doc_content += "\n\n"
        
        if asset_status.get('train_auc_ks_vs_epsilon.png', False):
            doc_content += "![AUC/KS vs éšç§é¢„ç®—](assets/train_auc_ks_vs_epsilon.png)\n\n"
        
        # æ€§èƒ½æ€»ç»“
        doc_content += "## 4. æ€§èƒ½æ€»ç»“\n\n"
        
        # PSIæ€§èƒ½
        if results['psi_summary'] is not None and len(results['psi_summary']) > 0:
            psi_data = results['psi_summary'].iloc[0]
            total_processed = self.format_number(psi_data.get('total_processed', 0))
            wall_clock_hours = psi_data.get('wall_clock_hours', 0)
            doc_content += f"**åäº¿çº§PSIåŸºå‡†æµ‹è¯•**:\n"
            doc_content += f"- âœ… **å¤„ç†è§„æ¨¡**: {total_processed} æ¡è®°å½•\n"
            doc_content += f"- âœ… **å®Œæˆæ—¶é—´**: {wall_clock_hours:.2f} å°æ—¶ (< 24å°æ—¶)\n"
            doc_content += f"- âœ… **å®Œæ•´æ€§éªŒè¯**: ç²¾åº¦ = 1.0ï¼ŒSHA256æ ¡éªŒé€šè¿‡\n\n"
        
        # è®­ç»ƒæ€§èƒ½
        if results['train_summary'] is not None and len(results['train_summary']) > 0:
            train_data = results['train_summary'].iloc[0]
            n_samples = self.format_number(train_data.get('n_samples', 0))
            wall_clock_hours = train_data.get('wall_clock_hours', 0)
            final_auc = train_data.get('final_auc', 0)
            final_ks = train_data.get('final_ks', 0)
            doc_content += f"**ç™¾ä¸‡çº§è”é‚¦è®­ç»ƒåŸºå‡†æµ‹è¯•**:\n"
            doc_content += f"- âœ… **æ ·æœ¬è§„æ¨¡**: {n_samples} æ ·æœ¬\n"
            doc_content += f"- âœ… **å®Œæˆæ—¶é—´**: {wall_clock_hours:.2f} å°æ—¶ (< 24å°æ—¶)\n"
            doc_content += f"- âœ… **æ¨¡å‹æ€§èƒ½**: AUC = {final_auc:.4f}, KS = {final_ks:.4f}\n\n"
        
        # æ–‡ä»¶æ¸…å•
        doc_content += "## 5. äº§å‡ºæ–‡ä»¶æ¸…å•\n\n"
        doc_content += "| æ–‡ä»¶è·¯å¾„ | æè¿° | SHA256 |\n"
        doc_content += "|----------|------|--------|\n"
        
        for file_path, sha256 in manifest.items():
            short_hash = sha256[:16]
            doc_content += f"| `{file_path}` | æµ‹è¯•æ•°æ®/å›¾è¡¨ | `{short_hash}...` |\n"
        
        # å¤ç°æŒ‡å—
        doc_content += "\n## 6. å¤ç°æŒ‡å—\n\n"
        doc_content += "```bash\n"
        doc_content += "# 1. å¯åŠ¨Rayé›†ç¾¤\n"
        doc_content += "./scripts/cluster_up.sh\n\n"
        doc_content += "# 2. è¿è¡ŒåŸºå‡†æµ‹è¯•\n"
        doc_content += "python bench/run_full_benchmark.py \\\n"
        doc_content += "  --psi-target 1000000000 \\\n"
        doc_content += "  --train-target 1000000 \\\n"
        doc_content += "  --workers 16\n\n"
        doc_content += "# 3. ç”Ÿæˆå›¾è¡¨\n"
        doc_content += "python tools/plot_bench.py --plot-type all\n\n"
        doc_content += "# 4. ç”Ÿæˆæ–‡æ¡£\n"
        doc_content += "python tools/generate_showcase_doc.py\n\n"
        doc_content += "# 5. åœæ­¢é›†ç¾¤\n"
        doc_content += "./scripts/cluster_down.sh\n"
        doc_content += "```\n\n"
        
        # ç»“å°¾
        doc_content += "---\n\n"
        doc_content += f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {timestamp}\n"
        doc_content += "**æµ‹è¯•ç¯å¢ƒ**: Rayé›†ç¾¤ (1 head + 16 workers)\n"
        doc_content += "**æ•°æ®å®Œæ•´æ€§**: æ‰€æœ‰æ•°å­—å‡å¯åœ¨ `reports/` ç›®å½•ä¸­æ‰¾åˆ°åŸå§‹æ•°æ®æ¥æº\n"
        doc_content += "**å›¾è¡¨å¯é‡ç°**: æ‰€æœ‰PNGå›¾è¡¨å‡å¯é€šè¿‡CSV/JSONLæ•°æ®é‡æ–°ç”Ÿæˆ\n"
        
        return doc_content
    
    def save_document(self, content: str) -> str:
        """ä¿å­˜æ–‡æ¡£åˆ°æ–‡ä»¶"""
        output_file = self.docs_dir / "pab-federated-showcase.md"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"å±•ç¤ºæ–‡æ¡£å·²ä¿å­˜: {output_file}")
            return str(output_file)
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def generate_full_showcase(self) -> str:
        """ç”Ÿæˆå®Œæ•´å±•ç¤ºæ–‡æ¡£"""
        logger.info("å¼€å§‹ç”Ÿæˆå®Œæ•´å±•ç¤ºæ–‡æ¡£...")
        
        try:
            # åŠ è½½æµ‹è¯•ç»“æœ
            results = self.load_test_results()
            
            # éªŒè¯èµ„æº
            asset_status = self.validate_assets()
            
            # ç”Ÿæˆæ–‡ä»¶æ¸…å•
            manifest = self.generate_file_manifest()
            
            # ç”Ÿæˆæ–‡æ¡£å†…å®¹
            doc_content = self.generate_showcase_document(results, asset_status, manifest)
            
            # ä¿å­˜æ–‡æ¡£
            output_file = self.save_document(doc_content)
            
            logger.info("âœ… å±•ç¤ºæ–‡æ¡£ç”Ÿæˆå®Œæˆ")
            return output_file
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå±•ç¤ºæ–‡æ¡£å¤±è´¥: {e}")
            raise

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”Ÿæˆè”é‚¦å­¦ä¹ åŸºå‡†æµ‹è¯•å±•ç¤ºæ–‡æ¡£")
    parser.add_argument("--project-root", default=".",
                       help="é¡¹ç›®æ ¹ç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = ShowcaseDocGenerator(args.project_root)
    
    try:
        # ç”Ÿæˆå±•ç¤ºæ–‡æ¡£
        output_file = generator.generate_full_showcase()
        
        print(f"\nâœ… å±•ç¤ºæ–‡æ¡£ç”ŸæˆæˆåŠŸ!")
        print(f"ğŸ“„ æ–‡æ¡£è·¯å¾„: {output_file}")
        print(f"\nğŸ“Š åŒ…å«å†…å®¹:")
        print(f"  - é¡¹ç›®æ€»è§ˆä¸æŠ€æœ¯æ¶æ„")
        print(f"  - PSIåŸºå‡†æµ‹è¯•ç»“æœä¸åˆ†æ")
        print(f"  - è”é‚¦è®­ç»ƒæ€§èƒ½è¯„ä¼°")
        print(f"  - å®Œæ•´å¤ç°æŒ‡å—")
        
        return 0
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")
        return 1

if __name__ == '__main__':
    exit(main())